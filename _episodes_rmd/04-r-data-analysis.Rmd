---
title: "R for Data Analysis"
source: Rmd
teaching: 150
exercises: 15
questions:
- "How can I summarize my data in R?"
- "How can R help make my research more reproducible?"
- "How can I combine two datasets from different sources?"
- "How can data tidying facilitate answering analysis questions?"
objectives:
- "To become familiar with the functions of the `dplyr` and `tidyr` packages."
- "To be able to use `dplyr` and `tidyr` to prepare data for analysis."
- "To be able to combine two different data sources using joins."
- "To be able to create plots and summary tables to answer analysis questions."
keypoints:
- "Package loading is an important first step in preparing an R environment."
- "Data analsyis in R facilitates reproducible research."
- "There are many useful functions in the `tidyverse` packages that can aid in data analysis."
- "Assessing data source and structure is an important first step in analysis."
- "Preparing data for analysis can take significant effort and planning."
---

```{r, include=FALSE}
source("../bin/chunk-options.R")
knitr_fig_path("04-")
```

### Contents

1.  [Getting started](#getting-started)
    -   [Loading in the data](#loading-in-the-data)
2.  [An introduction to data analysis in R using `dplyr`](#intro-data-analysis)
    -   [Get stats fast with `summarize()`](#get-stats-fast-with-summarize)
    -   [Narrow down rows with `filter()`](#narrow-down-rows-with-filter)
    -   [Grouping rows using `group_by()`](#grouping-rows-using-group_by)
    -   [Make new variables with `mutate()`](#make-new-variables-with-mutate)
    -   [Subset columns using `select()`](#subset-columns-using-select)
    -   [Changing the shape of the data](#changing-the-shape-of-the-data)
3.  [Cleaning up data](#cleaning-up-data)
4.  [Joining data frames](#joining-data-frames)
5.  [Analyzing combined data](#analyzing-combined-data)
6.  [Finishing with Git and GitHub](#Finishing-with-Git-and-GitHub)

# Getting Started

First, navigate to the un-reports directory however you'd like and open `un-report.Rproj`.
This should open the un-report R project in RStudio.
You can check this by seeing if the Files in the bottom right of RStudio are the ones in your `un-report` directory.

Yesterday we spent a lot of time making plots in R using the ggplot2 package. Visualizing data using plots is a very powerful skill in R, but what if we would like to work with only a subset of our data? Or clean up messy data, calculate summary statistics, create a new variable, or join two datasets together? There are several different methods for doing this in R, and we will touch on a few today using functions the `dplyr` package.

First, we will create a new RScript file for our work. Open RStudio. Choose "File" \> "New File" \> "RScript". We will save this file as `un_data_analysis.R`

### Loading in the data

We will start by importing the complete gapminder dataset that we used yesterday into our fresh new R session. Yesterday we did this using a "point-and-click" commands. Today let's type them into the console ourselves: `gapminder_data <- read_csv("data/gapminder_data.csv")`

> ## Exercise
>
> If we look in the console now, we'll see we've received an error message saying that R "could not find the function `read_csv()`". *Hint: Packages...*
>
> > ## Solution
> >
> > What this means is that R cannot find the function we are trying to call. The reason for this usually is that we are trying to run a function from a package that we have not yet loaded. This is a very common error message that you will probably see a lot when using R. It's important to remember that you will need to load any packages you want to use into R each time you start a new session. The `read_csv` function comes from the `readr` package which is included in the `tidyverse` package so we will just load the `tidyverse` package and run the import code again.
> {: .solution}
{: .challenge}

Now that we know what's wrong, We will use the `read_csv()` function from the Tidyverse `readr` package. Load the `tidyverse` package and gapminder dataset using the code below.

```{r InitDplyr}
library(tidyverse)
```

The output in your console shows that by doing this, we attach several useful packages for data wrangling, including `readr`. Check out these packages and their documentation at [tidyverse.org](https://www.tidyverse.org)

> **Reminder:** Many of these packages, including `dplyr` , come with "Cheatsheets" found under the **Help** RStudio menu tab.

Reload your data:

```{r ReloadGapminder}
gapminder_data <- read_csv("data/gapminder_data.csv")
```

Notice that the output of the `read_csv()` function is pretty informative. It tells us the name of all of our column headers as well as how it interpreted the data type. This birds-eye-view can help you take a quick look that everything is how we expect it to be.

Now we have the tools necessary to work through this lesson.

# An introduction to data analysis in R using `dplyr` {#intro-data-analysis}

## Get stats fast with `summarize()` {#get-stats-fast-with-summarize}

[*Back to top*](#contents)

Let's say we would like to know what is the mean (average) life expecteny in the dataset. R has a built in function function called `mean()` that will calculate this value for us. We can apply that function to our lifeExp column using the `summarize()` function. Here's what that looks like:
```{r AvgLifeExp}
summarize(gapminder_data, averageLifeExp=mean(lifeExp))
```

When we call `summarize()`, we can use any of the column names of our data object as values to pass to other functions. `summarize()` will return a new data object and our value will be returned as a column.

> **Note:** The `summarize()` and `summarise()` perform identical functions.

We name this new column so we can use in a future argument. So the `averageLifeExp=` part tells `summarize()` to use "averageLifeExp" as the name of the new column. Note that you don't have to quotes around this new name as long as it starts with a letter and doesn't include a space.

Instead of including the data as an argument, we can use the *pipe operator* `%>%` to pass the data value into the `summarize` function. 

```{r AvgLifeExpWithPipe}
gapminder_data %>% summarize(averageLifeExp=mean(lifeExp))
```
 
This line of code will do the exact same thing as our first summary command, but the piping function tells R to use the `gapminder_data` dataframe as the first argument in the next function.

This lets us "chain" together multiple functions, which will be helpful later. Note that the pipe (`%>%`) is a bit different from using the ggplot plus (`+`). Pipes take the output from the left side and use it as input to the right side. Plusses layer on additional information (right side) to a preexisting plot (left side). 
 
We can also add an <kdb>Enter</kdb> to make it look nicer:  
```{r AvgLifeExpWithPipe2}
gapminder_data %>%
  summarize(averageLifeExp=mean(lifeExp))
```

Using the *pipe operator* `%>%` and enter command makes our code more readable. The  *pipe operator* `%>%` also helps to avoid using nested function and minimizes the need for new variables.

Since we use the pipe operator so often, there is a keyboard shortcut for it in RStudio. You can press <kdb>Ctrl</kdb>+<kdb>Shift</kdb>+<kdb>M<kdb> on Windows or <kdb>Cmd<kdb>+<kdb>Shift<kdb>+<kdb>M<kdb> on a Mac.

> ## Pro tip: Saving a new dataframe
> Notice that when we run the following code, we are not actually saving a new variable: 
> ```{r AvgLifeExpWithPipe3, eval = FALSE}
> gapminder_data %>%
>   summarize(averageLifeExp=mean(lifeExp))
> ```
> This simply outputs what we have created, but does not change actually change `gapminder_data` or save a new dataframe. To save a new dataframe, we could run: 
> ```{r saveNewDF, eval = FALSE}
> gapminder_data_summarized <- gapminder_data %>%
>   summarize(averageLifeExp=mean(lifeExp))
> ```
> Or if we want to change `gapminder_data` itself: 
> ```{r overwriteDF, eval = FALSE}
> gapminder_data <- gapminder_data %>%
>   summarize(averageLifeExp=mean(lifeExp))
> ```
> IMPORTANT: This would overwrite the existing `gapminder_data` object. 
> 
> For now, we will not be saving dataframes, since we are just experimenting with `dyplr` functions, but it will be useful later on in this lesson. 
> 
{: .callout}

## Narrow down rows with `filter()` {#narrow-down-rows-with-filter}

[*Back to top*](#contents)

Let's take a look at the value we just calculated, which tells us the average life expectancy for all rows in the data was 59.5. That seems a bit low, doesn't it? What's going on?

Well, remember the dataset contains rows from many different years and many different countries. It's likely that life expectancy has increased overtime, so it may not make sense to average over all the years at the same time.

Use `summarize()` to find the most recent year in the data set. We can use the `max()` function to return the maximum value.

> ## Practice using the `%>%` to summarize data
>
> Find the mean population using the piping function.
>
> > ## Solution:
> >
> > ```{r PipeExercise}
> > gapminder_data %>%  
> >  summarize(recent_year = max(year))
> > ```
> > 
> {: .solution}
{: .challenge}

So we see that the most recent year in the dataset is 2007. Let's calculate the life expectancy for all countries for only that year. To do that, we will use the `filter()` function to only use rows for that year before calculating the mean value.

```{r GapRecentLifeExp}
gapminder_data %>%
  filter(year == 2007) %>%
  summarize(average=mean(lifeExp))
```

> ## Filtering the dataset
>
> What is the average GDP per capita for the first year in the dataset? *Hint: the column headers identified by `read_csv()` showed us there was a column called gdpPercap in the dataset*
>
> > ## Solution
> >
> > Identify the earliest year in our dataset using `min()` and `summarize()`
> >
> > ```{r FilterChallenge1}
> > gapminder_data %>%
> > summarize(first_year=min(year))
> > ```
> >
> > We see here that the first year in the dataset is 1952. Filter to only 1952, and determin the average GDP per capita.
> >
> > ```{r FilterChallenge2}
> > gapminder_data %>%
> > filter(year == 1952) %>%
> > summarize(average_gdp=mean(gdpPercap))
> > ```
> > {: .source}
> > By combining `filter()` and `summarize()` we were able to calculate the mean GDP per capita in the year 1952.
> {: .solution}
{: .challenge}

Notice how the pipe operator (`%>%`) allows us to combine these two simple steps into a more complicated data extraction?. We took the data, filtered out the rows, then took the mean value. The argument we pass to `filter()` needs to be some expression that will return TRUE or FALSE. We can use comparisons like `>` (greater than) and `<` (less than) for example. Here we tested for equality using a double equals sign `==`. You use `==` (double equals) when testing if two values are equal, and you use `=` (single equals) when naming arguments that you are passing to functions. Try changing it to use `filter(year = 2007)` and see what happens.

## Grouping rows using `group_by()` {#grouping-rows-using-group_by}

[*Back to top*](#contents)

We see that the life expectancy in 2007 is much larger than the value we got using all of the rows. It seems life expectancy is increasing which is good news. But now we might be interested in calculating the average for each year. Rather that doing a bunch of different `filter()` statements, we can instead use the `group_by()` function. The function allows us to tell the code to treat the rows in logical groups, so rather than summarizing over all the rows, we will get one summary value for each group. Here's what that will look like:

```{r GapLifeExpByYear}
gapminder_data %>%
  group_by(year) %>%
  summarize(average=mean(lifeExp))
```

The `group_by()` function expects you to pass in the name of a column (or multiple columns separated by comma) in your data. 

Note that you might get a message about the summarize function regrouping the output by 'year'. This simply indicates what the function is grouping by. 

> ## Grouping the data
>
> Try calculating the average life expectancy by continent.
>
> > ## Solution
> >
> > ```{r GroupByChallenge1}
> > gapminder_data %>%
> > group_by(continent) %>%
> > summarize(average=mean(lifeExp))
> > ```
> > {: .source}
> >
> > By combining `group_by()` and `summarize()` we are able to calculate the mean life expectancy by continent.
> {: .solution}
{: .challenge}

You can also create more than one new column when you call `summarize()`. To do so, you must separate your columns with a comma. Building on the code from the last exercise, let's add a new column that calculates the minimum life expectancy for each continent. 

```{r GapLifeExpMinMax}
gapminder_data %>%
  group_by(continent) %>%
  summarize(average=mean(lifeExp), min=min(lifeExp))
```


## Make new variables with `mutate()` {#make-new-variables-with-mutate}

[*Back to top*](#contents)

Each time we ran `summarize()`, we got back fewer rows than passed in. We either got one row back, or one row per group. But sometimes we want to create a new column in our data without changing the number of rows. The function we use to create new columns is called `mutate()`.

We have a column for the population and the GDP per capita. If we wanted to get the total GDP, we could multiply the per capita GDP values by the total population. Here's what such a `mutate()` command would look like:

```{r GapMutate}
gapminder_data %>%
  mutate(gdp = pop * gdpPercap)
```

This will add a new column called "gdp" to our data. We use the column names as if they were regular values that we want to perform mathematical operations on and provide the name in front of an equals sign like we have done with `summarize()`

> ## `mutate()`
> We can also multiply by constants or other numbers using mutate - remember how in the plotting lesson we made a plot with population in millions? Try making a new column for this dataframe called popInMillions that is the population in million. 
> 
> > ## Solution: 
> > ```{r mutateExercise}  
> > gapminder_data %>%  
> > mutate(gdp = pop * gdpPercap, popInMillions = pop / 1000000)  
> > ```  
> {: .solution}
{: .challenge}
 

## Subset columns using `select()` {#subset-columns-using-select}

[*Back to top*](#contents)

We use the `filter()` function to choose a subset of the rows from our data, but when we want to choose a subset of columns from our data we use `select()`. For example, if we only wanted to see the population ("pop") and year values, we can do:

```{r GapSelect}
gapminder_data %>%
  select(pop, year)
```

We can also use `select()` to drop/remove particular columns by putting a minus sign (`-`) in front of the column name. For example, if we want everything but the continent column, we can do:

```{r GapSelectDrop}
gapminder_data %>%
  select(-continent)
```

> ## selecting columns 
> Create a dataframe with only the `country`, `continent`, `year`, and `lifeExp` columns. 
> 
> > ## Solution: 
> > There are multiple ways to do this exercise. Here are two different possibilities. 
> > 
> > ```{r selectExerciseOption1}
> > gapminder_data %>%
> >   select(country, continent, year, lifeExp)
> > ```
> > ```{r selectExerciseOption2}
> > gapminder_data %>%
> >   select(-pop, -gdpPercap)
> > ```
> {: .solution}
{: .challenge}


> ## Bonus: Using helper functions with `select()`
>
> The `select()` function has a bunch of helper functions that are handy if you are working with a dataset that has a lot of columns. You can see these helper functions on the `?select` help page. For example, let's say we wanted to select the year column and all the columns that start with the letter "c". You can do that with:
> 
> ```{r GapSelectFancy}
> gapminder_data %>%
>   select(year, starts_with("c"))
> ```
> This returns just the three columns we are interested in. 
>
> > ## Using `select()` with a helper function
> >
> > Find a helper function on the help page that will choose all the columns that have "p" as their last letter (ie: "pop","lifeExp","gdpPerCap")
> >
> > > ## Solution
> > >
> > > The helper function `ends_with()` can help us here.
> > >
> > > ```{r GroupByChallenge2}
> > > gapminder_data %>%
> > > select(ends_with("p"))
> > > ```
> > {: .solution}
> {: .challenge}
> 
{: .solution}


## Changing the shape of the data

[*Back to top*](#contents)

Data comes in many shapes and sizes, and one way we classify data is either "wide" or "long." Data that is "long" has one row per observation. The gapminder_data data is in a long format. We have one row for each country for each year and each different measurement for that country is in a different column. We might describe this data as "tidy" because it makes it easy to work with `ggplot2` and `dplyr` functions (this is where the "tidy" in "tidyverse" comes from). As tidy as it may be, sometimes we may want our data in a "wide" format. Typically in "wide" format each row represents a group of observations and each value is placed in a different column rather than a different row. For example maybe we want only one row per country and want to spread the life expectancy values into different columns (one for each year).

The `tidyr` package contains the functions `pivot_wider` and `pivot_longer` that make it easy to switch between the two formats. The `tidyr` package is included in the `tidyverse` package so we don't need to do anything to load it.

```{r PivotWider}
gapminder_data %>%
  select(country, continent, year, lifeExp) %>%
  pivot_wider(names_from = year, values_from = lifeExp )
```

Notice here that we tell `pivot_wider()` which columns to pull the names we wish our new columns to be named from the year variable, and the values to populate those columns from the lifeExp variable. (Again, neither of which have to be in quotes in the code when there are no special characters or spaces - certainly an incentive not to use special characters or spaces!) We see that the resulting table has new columns by year, and the values populate it with our remaining variables dictating the rows.

Before we move on to more data cleaning, let's create the final gapminder dataframe we will be working with for the rest of the lesson! 

> ## Final Americas 2007 gapminder dataset
> Read in the `gapminder_data.csv` file, filter out the year 2007 and the continent "Americas." Then drop the `year` and `continent` columns from the dataframe. Then save the new dataframe into a variable called `gapminder_data_2007`. 
> 
> > ## Solution: 
> > ```{r LoadGapminder2007_solution}
> > gapminder_data_2007 <- read_csv("data/gapminder_data.csv") %>%
> >   filter(year == 2007 & continent == "Americas") %>%
> >   select(-year, -continent)
> > ```
> {: .solution}
{: .challenge}

Awesome! This is the dataframe we will be using later on in this lesson. 


## Reviewing Git and GitHub
Now that we have our gapminder data prepared, let's use what we learned about git and GitHub in the previous lesson to add, commit, and push our changes.  

Open Terminal/Git Bash, if you do not have it open already. First we'll need to navigate to our un-report directory.

Let's start by print our current working directory and listing the items in the directory, to see where we are. 
``` 
pwd
ls
```

Now, we'll navigate to the un-report directory. 
```
cd ~/Desktop/un-report  
ls
```

To start, let's pull to make sure our local repository is up to date. 
```
git status
git pull
```

Not let's add and commit our changes. 
```
git status
git add
git status "un_data_analysis.R"  
git commit -m "Create data analysis file"  
```

Finally, let's check our commits and then push the commits to GitHub. 
```
git status
git log --online  
git push 
git status
``` 

# Cleaning up data

[*Back to top*](#contents)

Researchers are often pulling data from several sources, and the process of making data compatible with one another and prepared for analysis can be a large undertaking. Luckily, there are many functions that allow us to do this in R. We've been working with the gapminder dataset, which contains population and GDP data by year. In this section, we practice cleaning and preparing a second dataset containing CO2 emissions data by country and year, sourced from [the UN](https://data.un.org/_Docs/SYB/CSV/SYB63_310_202009_Carbon%20Dioxide%20Emission%20Estimates.csv).

It's always good to go into data cleaning with a clear goal in mind. Here, we'd like to prepare the CO2 UN data to be compatible with our gapminder data so we can directly compare GDP to CO2 emissions. To make this work, we'd like a data frame that contains a column with the country name, and columns for different ways of measuring CO2 emissions. We will also want the data to be collected as close to 2007 as possible (the last year we have data for in gapminder). Let's start with reading the data in using `read_csv()`

```{r CleanEmissionsData}
read_csv("data/co2-un-data.csv")
```

The output gives us a warning about missing column names being filled in with things like 'X3', 'X4', etc. Looking at the table that is outputted by `read_csv()` we can see that there appear to be two rows at the top of the file that contain information about the data in the table. The first is a header that tells us the table number and its name. Ideally, we'd skip that. We can do this using the `skip=` argument in read_csv by giving it a number of lines to skip.

```{r CleanEmissionsSkip}
read_csv("data/co2-un-data.csv", skip=1)
```

Now we get a similar Warning message as before, but the outputted table looks better.

> ## Warnings and Errors
> It's important to differentiate between Warnings and Errors in R. A warning tells us, "you might want to know about this issue, but R still did what you asked". An error tells us, "there's something wrong with your code or your data and R didn't do what you asked". You need to fix any errors that arise. Warnings, are probably best to resolve or at least understand why they are coming up.
{.callout}

We can resolve this warning by telling `read_csv()` what the column names should be with the `col_names()` argument where we give it the column names we want within the c() function separated by commas. If we do this, then we need to set skip to 2 to also skip the column headings. Let's also save this dataframe to `co2_emissions_dirty` so that we don't have to read it in every time we want to clean it even more.

```{r CleanEmissionsColNames1}
co2_emissions_dirty <- read_csv("data/co2-un-data.csv", skip=2,
         col_names=c("region", "country", "year", "series", "value", "footnotes", "source"))
co2_emissions_dirty
```

> ## Bonus: Another way to deal with this error
> 
> There are often multiple ways to clean data. Here we  read in the table, get the warning and then fix the column names using the rename function.
> 
> ```{r CleanEmissionsRename}
> read_csv("data/co2-un-data.csv", skip=1) %>%
>   rename(country=X2)
> ```
>
> Many data analysts prefer to have their column headings and variable names be in all lower case. We can use a variation of `rename()`, which is `rename_all()` that allows us to set all of the column headings to lower case by giving it the name of the tolower function, which makes everything lowercase.
> 
> ```{r CleanEmissionsRenameLower}
> read_csv("data/co2-un-data.csv", skip=1) %>%
>  rename_all(tolower)
> ```
{: .solution}

We previously saw how we can subset columns from a data frame using the select function. There are a lot of columns with extraneous information in this dataset, let's subset out the columns we are interested in. 

> ## Reviewing selecting columns
> Select the country, year, series, and value columns from our dataset. 
> 
> > ## Solution: 
> > ```{r CleanEmissionsSelect}
> > 
> > co2_emissions_dirty %>%
> >   select(country, year, series, value)
> > ```
> {: .solution}
{: .challenge}

The series column has two methods of quantifying CO2 emissions - "Emissions (thousand metric tons of carbon dioxide)" and "Emissions per capita (metric tons of carbon dioxide)". Those are long titles that we'd like to shorten to make them easier to work with. We can shorten them to "total_emissions" and "per_capita_emissions" using the recode function. We need to do this within the mutate function where we will mutate the series column. The syntax in the recode function is to tell recode which column we want to recode and then what the old value (e.g. "Emissions (thousand metric tons of carbon dioxide)") should equal after recoding (e.g. "total").

```{r CleanEmissionsMutateRecode}
co2_emissions_dirty %>% 
  select(country, year, series, value) %>%
  mutate(series = recode(series, "Emissions (thousand metric tons of carbon dioxide)" = "total_emissions",
                         "Emissions per capita (metric tons of carbon dioxide)" = "per_capita_emissions"))
```

Recall that we'd like to have separate columns for the two ways that we CO2 emissions data. To achieve this, we'll use the pivot_wider function that we saw previously. The columns we want to spread out are series (i.e. names_from) and value (i.e. values_from).

```{r CleanEmissionsPivotWider}
co2_emissions_dirty %>%
  select(country, year, series, value) %>%
  mutate(series = recode(series, "Emissions (thousand metric tons of carbon dioxide)" = "total_emission",
                         "Emissions per capita (metric tons of carbon dioxide)" = "per_capita_emission")) %>%
  pivot_wider(names_from=series, values_from=value)
```

Excellent! The last step before we can join this data frame is to get the most data that is for the year closest to 2007 so we can make a more direct comparison to the most recent data we have from gapminder. For the sake of time, we'll just tell you that we want data from 2005. 

> ## Bonus: How did we determine that 2005 is the closest year to 2007? 
> 
> We want to make sure we pick a year that is close to 2005, but also a year that has a decent amount of data to work with. One useful tool is the `count()` function, which will tell us how many times a value is repeated in a column of a data frame. Let's use this function on the year column to see which years we have data for and to tell us whether we have a good number of countries represented in that year.
> 
> ```{r CleanEmissionsyearCountryCount}
> co2_emissions_dirty %>%
>  select(country, year, series, value) %>%
>  mutate(series = recode(series, "Emissions (thousand metric tons of carbon dioxide)" = "total",
>                         "Emissions per capita (metric tons of carbon dioxide)" = "per_capita")) %>%
>   pivot_wider(names_from=series, values_from=value) %>%
>  count(year)
> ```
> 
> It looks like we have data for 140 countries in 2005 and 2010. We chose 2005 because it is closer to 2007. 
{: .solution}


> ## Filtering rows and removing columns
> Filter out data from 2005 and then drop the year column. (Since we will have only data from one year, it is now irrelevant.)
> 
> > ## Solution: 
> > ```{r CleanEmissionsByYear}
> > co2_emissions_dirty %>%
> >  select(country, year, series, value) %>%
> >  mutate(series = recode(series, "Emissions (thousand metric tons of carbon dioxide)" = "total",
> >                         "Emissions per capita (metric tons of carbon dioxide)" = "per_capita")) %>%
> >  pivot_wider(names_from=series, values_from=value) %>%
> >  filter(year==2005) %>%
> >  select(-year)
> > ```
> {: .solution}
{: .challenge}


Finally, let's go ahead and assign the output of this code chunk, which is the cleaned dataframe, to a variable name:

```{r AssignCleanEmissions}
co2_emissions <- co2_emissions_dirty %>%
  select(country, year, series, value) %>%
  mutate(series = recode(series, "Emissions (thousand metric tons of carbon dioxide)" = "total_emission",
                         "Emissions per capita (metric tons of carbon dioxide)" = "per_capita_emission")) %>%
  pivot_wider(names_from=series, values_from=value) %>%
  filter(year==2005) %>%
  select(-year)
```

> **Looking at your data:** You can get a look at your data-cleaning hard work by navigating to the **Environment** tab in RStudio and clicking the table icon next to the variable name. Notice when we do this, RStudio automatically runs the `View()` command. We've made a lot of progress!
{.callout}

# Joining data frames

[*Back to top*](#contents)


Now we're ready to join our CO2 emissions data to the gapminder data. Previously we saw that we could read in and filter the gapminder data like this to get the data from the Americas for 2007 so we can create a new dataframe with our filtered data:

```{r LoadGapminder2007}
gapminder_data_2007 <- read_csv("data/gapminder_data.csv") %>%
  filter(year == 2007 & continent == "Americas") %>%
  select(-year, -continent)
```

Look at the data in `co2_emissions` and `gapminder_data_2007`. If you had to merge these two data frames together, which column would you use to merge them together? If you said "country" - good job!

We'll call country our "key". Now, when we join them together, can you think of any problems we might run into when we merge things? We might not have CO2 emissions data for all of the countries in the gapminder dataset and vice versa. Also, a country might be represented in both data frames but not by the same name in both places. As an example, write down the name of the country that the University of Michigan is in - we'll come back to your answer shortly!

The dplyr package has a number of tools for joining data frames together depending on what we want to do with the rows of the data of countries that are not represented in both data frames. Here we'll be using `inner_join()` and `anti_join()`. 

In an "inner join", the new data frame only has those rows where the same key is found in both data frames. This is a very commonly used join.

![]({{ page.root }}/fig/r-data-analysis/join-inner.png)

> ## Bonus: Other dplyr join functions 
>
> Outer joins and can be performed using `left_join()`, `right_join()`, and `full_join()`. In a "left join", if the key is present in the left hand data frame, it will appear in the output, even if it is not found in the the right hand data frame. For a right join, the opposite is true. For a full join, all possible keys are included in the output data frame.
> 
> ![]({{ page.root }}/fig/r-data-analysis/join-outer.png)
{: .solution}

Let's give the `inner_join()` function a try.
```{r InnerJoin}
inner_join(gapminder_data, co2_emissions)
```

Do you see that we now have data from both data frames joined together in the same data frame? One thing to note about the output is that `inner_join()` tells us that that it joined by "country". We can make this explicit using the "by" argument in the join functions

```{r InnerJoinByCountry}
inner_join(gapminder_data, co2_emissions, by="country")
```

One thing to notice is that gapminder data had 25 rows, but the output of our join only had 21. Let's investigate. It appears that there must have been countries in the gapminder data that did not appear in our co2_emissions data frame. 

Let's use `anti_join()` for this - this will show us the data for the keys on the left that are missing from the data frame on the right. 

```{r AntiJoin}
anti_join(gapminder_data, co2_emissions, by="country")
```
We can see that the co2_emissions data were missing for Bolivia, Puerto Rico, United States, and Venezuela. 

If we look at the co2_emissions data with `View()`, we will see that Bolivia, United States, and Venezuela are called different things in the co2_emissions data frame. They're called "Bolivia (Plurin. State of)", "United States of America", and "Venezuela (Boliv. Rep. of)". Puerto Rico isn't a country; it's part of the United States. Using `mutate()` and `recode()`, we can re-import the co2_emissions data so that the country names for Bolivia, United States, and Venezuela, match those in the gapminder data.

```{r Co2Recode}
co2_emissions <- read_csv("data/co2-un-data.csv", skip=2,
                          col_names=c("region", "country", "year",
                                      "series", "value", "footnotes", "source")) %>%
  select(country, year, series, value) %>%
  mutate(series = recode(series, "Emissions (thousand metric tons of carbon dioxide)" = "total",
                         "Emissions per capita (metric tons of carbon dioxide)" = "per_capita")) %>%
  pivot_wider(names_from=series, values_from=value) %>%
  filter(year==2005) %>%
  select(-year) %>%
  mutate(country=recode(country,
                        "Bolivia (Plurin. State of)" = "Bolivia",
                        "United States of America" = "United States",
                        "Venezuela (Boliv. Rep. of)" = "Venezuela")
  )

anti_join(gapminder_data, co2_emissions, by="country")
```

Now we see that our recode enabled the join for all countries in the gapminder, and we are left with Puerto Rico. In the next exercise, let's recode Puerto Rico as United States in the gapminder data and then use `group_by()` and `summarize()` to aggregate the data; we'll use the population data to weight the life expectancy and GDP values.


In the gapminder data, let's recode Puerto Rico as United States. 
```{r RecodePR}
gapminder_data <- read_csv("data/gapminder_data.csv") %>%
filter(year == 2007 & continent == "Americas") %>%
select(-year, -continent) %>%
mutate(country = recode(country, "Puerto Rico" = "United States")) 
```

Now we have to group Puerto Rico and the US together, aggregating and calculating the data for all of the other columns. This is a little tricky - we will need a weighted average of lifeExp and gdpPercap. 

```{r RecodeJoinExercise2}
gapminder_data <- read_csv("data/gapminder_data.csv") %>%
  filter(year == 2007 & continent == "Americas") %>%
  select(-year, -continent) %>%
  mutate(country = recode(country, "Puerto Rico" = "United States")) %>%
  group_by(country) %>%
  summarize(lifeExp = sum(lifeExp * pop)/sum(pop),
            gdpPercap = sum(gdpPercap * pop)/sum(pop),
            pop = sum(pop)
  )
```

Let's check to see if it worked! 
```{r anticheckPRJoin}
anti_join(gapminder_data, co2_emissions, by="country")
```
Now our `anti_join()` returns an empty data frame, which tells us that we have reconciled all of the keys from the gapminder data with the data in the co2_emissions data frame.

Finally, let's use the `inner_join()` to create a new data frame:

```{r CleanInnerJoin}
gapminder_co2 <- inner_join(gapminder_data, co2_emissions, by="country")
```

One last thing! What if we're interested in distinguishing between countries in North America and South America? We want to create two groups - Canada, the United States, and Mexico in one and the other countries in another.  

We can create a grouping variable using `mutate()` combined with an `if_else()` function - a very useful pairing.  
 
```{r GapRegion1}  
gapminder_co2 %>%  
mutate(region = if_else(country == "Canada" | country == "United States" | country == "Mexico", "north", "south"))  
```  
Let's look at the output - see how the Canada, US, and Mexico rows are all labeled as "north" and everything else is labeled as "south"  

We have reached our data cleaning goals! One of the best aspects of doing all of these steps coded in R is that our efforts are reproducible, and the raw data is maintained. With good documentation of data cleaning and analysis steps, we could easily share our work with another researcher who would be able to repeat what we've done. However, it's also nice to have a saved `csv` copy of our clean data. That way we can access it later without needing to redo our data cleaning, and we can also share the cleaned data with collaborators. To save our dataframe, we'll use `write_csv()`. 

```{r writeCSV}
write_csv(gapminder_co2, "data/gapminder_co2.csv")
```

Great - Now we can move on to the analysis! 

# Analyzing combined data

[*Back to top*](#contents)

For our analysis, we have two questions we'd like to answer. First, is there a relationship between the GDP of a country and the amount of CO2 emitted (per capita)? Second, Canada, the United States, and Mexico account for nearly half of the population of the Americas. What percent of the total CO2 production do they account for?

To answer the first question, we'll plot the CO2 emitted (on a per capita basis) against the GDP (on a per capita basis) using a scatter plot:

```{r PlotPercapCO2vsGDP}
ggplot(gapminder_co2, aes(x=gdpPercap, y=per_capita)) +
  geom_point() +
  labs(x="GDP (per capita)",
       y="CO2 emitted (per capita)",
       title="There is a strong association between a nation's GDP \nand the amount of CO2 it produces"
  )
```

*Tip:* Notice we used the `\n` in our title to get a new line to prevent it from getting cut off.

To help clarify the association, we can add a fit line through the data using `geom_smooth()`

```{r PlotPercapCO2vsGDPSmooth}
ggplot(gapminder_co2, aes(x=gdpPercap, y=per_capita)) +
  geom_point() +
  labs(x="GDP (per capita)",
       y="CO2 emitted (per capita)",
       title="There is a strong association between a nation's GDP \nand the amount of CO2 it produces"
  ) +
  geom_smooth()
```

We can force the line to be straight using `method="lm"` as an argument to `geom_smooth`

```{r PlotPercapCO2vsGDP1SmoothLm}
ggplot(gapminder_co2, aes(x=gdpPercap, y=per_capita)) +
  geom_point() +
  labs(x="GDP (per capita)",
       y="CO2 emitted (per capita)",
       title="There is a strong association between a nation's GDP \nand the amount of CO2 it produces"
  ) +
  geom_smooth(method="lm")
```

To answer our first question, as the title of our plot indicates there is indeed a strong association between a nation's GDP and the amount of CO2 it produces.

For the second question, we want to create two groups - Canada, the United States, and Mexico in one and the other countries in another.

We can create a grouping variable using `mutate()` combined with an `if_else()` function - a very useful pairing.

```{r GapRegion2}
gapminder_co2 %>%
  mutate(region = if_else(country == "Canada" | country == "United States" | country == "Mexico", "north", "south"))
```

Now we can use this column to repeat our `group_by()` and `summarize()` steps

```{r GapRegionGroupSummary}
gapminder_co2 %>%
  mutate(region = if_else(country == "Canada" |
                            country == "United States" |
                            country == "Mexico", "north", "south")) %>%
  group_by(region) %>%
  summarize(sumtotal = sum(total),
            sumpop = sum(pop))
```

The `if_else()` statement reads like, "if country equals "Canada" OR `|` "United states" OR "Mexico", the new variable region should be "north", else "south"". It's worth exploring logical operators for "or" `|`, "and" `&&`, and "not" `!`, which opens up a great deal of possibilities for writing code to do what you want.

We see that although Canada, the United States, and Mexico account for close to half the population of the Americas, they account for 88% of the CO2 emitted. We just did this math quickly by plugging the numbers from our table into the console to get the percentages. Can we make that a little more reproducible by calculating percentages for population (pop) and total emissions (total) into our data before summarizing?


## Finishing with Git and GitHub

Awesome work! Let's make sure it doesn't go to waste. Time to add, commit, and push our changes to GitHub again - do you remember how?

> ## changing directories
> Print your current working directory and list the items in the directory to check where you are. If you are not in the un-report directory, navigate there. 
> > ## Solution: 
> > ```
> > pwd  
> > ls 
> > cd ~/Desktop/un-report  
> > ls
> > ```
> {: .solution}
{: .challenge}

> ## reviewing git and GitHub
> 
> Pull to make sure our local repository is up to date. Then add, commit, and push your commits to GitHub. Don't forget to check your git status periodically to make sure everything is going as expected! 
> 
> > ## Solution: 
> > ```
> > git status 
> > git pull
> > git status 
> > git add "data-analysis.R"  
> > git status 
> > git commit -m "Create data analysis file"  
> > git status 
> > git log --online  
> > git push
> > git status 
> > ```
> {: .solution}
{: .challenge}


# Bonus 

## Bonus content

### Sort data with `arrange()`

The `arrange()` function allows us to sort our data by some value. Let's use the `gapminder_data` dataframe. We will take the average value for each continent in 2007 and then sort it so the continents with the longest life expectancy are on top. Which continent might you guess has be highest life expectancy before running the code?

The helper function `ends_with()` can help us here.
```{r GapLifeContinentArrange}
gapminder_data %>%
 filter(year==2007) %>%
 group_by(continent) %>%
 summarise(average= mean(lifeExp)) %>%
 arrange(desc(average))
```

Notice there that we can use the column created the in the `summarize()` step ("average") later in the `arrange()` step. We also use the `desc()` function here to sort the values in a descending order so the largest values are on top. The default is to put the smallest values on top.


## Bonus exercises

> ## Calculating percent
>
> What percentage of the population and CO2 emissions in the Americas does the United States make up? What percentage of the population and CO2 emission does North America make up? 
>
> > ## Solution
> >
> > Create a new variable using `mutate()` that calculates percentages for the pop and total variables.
> >
> > ```{r PopPercExercise}
> > gapminder_co2 %>%
> >   mutate(region = if_else(country == "Canada" | country == "United States" | country == "Mexico", "north", "south")) %>%
> >   mutate(totalPercent = total/sum(total)*100,
> >          popPercent = pop/sum(pop)*100)
> > ```
> >
> > This table shows that the United states makes up 33% of the population of the Americas, but accounts for 77% of total emissions. Now let's take a look at population and emission for the two different continents: 
> >
> > ```{r}
> > gapminder_co2 %>%
> >   mutate(region = if_else(country == "Canada" | country == "United States" | country == "Mexico", "north", "south")) %>%
> >   mutate(totalPercent = total/sum(total)*100,
> >          popPercent = pop/sum(pop)*100) %>%
> >   group_by(region) %>%
> >   summarize(sumTotalPercent = sum(totalPercent),
> >             sumPopPercent = sum(popPercent))
> > ```
> > 
> {: .solution}
{: .challenge}



> ## CO2 bar plot
> Create a bar plot of the percent of emissions for each country, colored by north and south america (HINT: use geom_col())  
> > ## Solution 
> > ```{r}
> > gapminder_co2 %>% ggplot(aes(x = country, y = total_emissionsPercent, fill = region)) +  
> > geom_col()  
> > ```
> {: .solution}
> 
> Now rotate the x-labels by 90 degrees (if you don't remember how, google it again or look at our code from the ggplot lesson)  
> 
> > ## Solution 
> > ```{r}
> > gapminder_co2 %>% ggplot(aes(x = country, y = total_emissionsPercent, fill = region)) +  
> > geom_col() +  
> > theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) 
> > ```
> {: .solution}
> 
> Reorder the bars in descending order. **Hint:** try Googling how to use the `reorder()` function with ggplot.
> > ## Solution 
> > ```{r}
> > gapminder_co2 %>% ggplot(aes(x = reorder(country, - total_emissionsPercent), y = total_emissionsPercent, fill = region)) +  
> > geom_col() +  
> > theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) 
> > ```
> {: .solution}
> 
> Practice making it look pretty! 
{: .challenge}


> ## low emissions
> Find the 3 countries with lowest per capita emissions. **Hint:** use the `arrange()` function. 
> 
> > ## Solution 
> > ```{r} 
> > gapminder_co2 %>% arrange(per_capita_emissions)  
> > ```
> {: .solution}
> 
> Create a bar chart for the per capita emissions for just those three countries. 
> > ## Solution 
> > ```{r} 
> > gapminder_co2 %>% filter(country == "Haiti" | country == "Paraguay" | country == "Nicaragua") %>%  
> > ggplot(aes(x = country, y = per_capita_emissions)) +  
> > geom_col() 
> > ```
> {: .solution}
> 
> Reorder them in descending order. **Hint:** use the `reorder()` function. 
> > ## Solution 
> > ```{r} 
> > gapminder_co2 %>% filter(country == "Haiti" | country == "Paraguay" | country == "Nicaragua") %>%  
> > ggplot(aes(x = reorder(country, - per_capita_emissions), y = per_capita_emissions)) +  
> > geom_col() 
> > ```
> {: .solution}
{: .challenge}
